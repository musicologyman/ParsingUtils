{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "judicial-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from os.path import expanduser, isfile, join, realpath\n",
    "from pprint import pprint\n",
    "from sqlite3 import Connection\n",
    "\n",
    "import pyperclip\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "DOWNLOADS_DIR = realpath(expanduser(\"~/Downloads\"))\n",
    "TEMP_DIR = expanduser(\"~/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "auburn-prospect",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_filename(filename):\n",
    "    if filename.startswith(\"~\"):\n",
    "        return expanduser(filename)\n",
    "    else:\n",
    "        return filename\n",
    "    \n",
    "def with_resolution(function):\n",
    "    def resolution_function(filename, *args, **kwargs):\n",
    "        resolved_name = resolve_filename(filename)\n",
    "        return function(resolved_name, *args, **kwargs)\n",
    "    return resolution_function\n",
    "\n",
    "def with_real_path(function):\n",
    "    def wrapped_function(filename, *args, **kwargs):\n",
    "        real_path = realpath(filename)\n",
    "        return function(real_path, *args, **kwargs)\n",
    "    return wrapped_function\n",
    "\n",
    "# def resolve_link(filename):\n",
    "#     if os.path.islink(filename):\n",
    "#         return os.readlink(filename)\n",
    "#     else:\n",
    "#         return filename\n",
    "\n",
    "@with_resolution\n",
    "def read_all_lines(filename, delete_trailing_carriage_returns=True):\n",
    "    with open(filename, mode=\"rt\") as fp:\n",
    "        if delete_trailing_carriage_returns:\n",
    "            return [line[:-1] for line in  fp.readlines()]\n",
    "        else:\n",
    "            return fp.readlines()\n",
    "        \n",
    "def remove_empty_and_whitespace_lines(lines):\n",
    "    return [line for line in lines if len(line.strip()) > 0]\n",
    "\n",
    "@with_resolution\n",
    "def write_csv(filename, fieldnames, rows):\n",
    "    with open(filename, mode=\"w\", newline=\"\") as fp:\n",
    "        writer = csv.DictWriter(fp, fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "        \n",
    "@with_resolution\n",
    "def change_ext(filename, new_ext):\n",
    "    filename_wo_ext, _ = os.path.splitext(filename)\n",
    "    if new_ext[0] == \".\":\n",
    "        return f\"{filename_wo_ext}{new_ext}\"\n",
    "    else:\n",
    "        return f\"{filename_wo_ext}.{new_ext}\"\n",
    "\n",
    "def list_files(directory=\".\", filter=lambda f:f):\n",
    "    for f in sorted(os.listdir(directory), key=lambda s : s.lower()):\n",
    "        if isfile(f) and filter(f):\n",
    "            print(f)\n",
    "            \n",
    "@with_resolution\n",
    "def read_text_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        return fp.read()\n",
    "            \n",
    "@with_resolution\n",
    "def read_html_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        return BeautifulSoup(filename, \"html.parser\")\n",
    "    \n",
    "def read_html_text(html_text):\n",
    "        return BeautifulSoup(html_text, \"html.parser\")\n",
    "    \n",
    "def list_to_string(input_list):\n",
    "    bytes_written = 0\n",
    "    with io.StringIO() as sp:\n",
    "        for line in input_list:\n",
    "            bytes_written += sp.write(f\"{line}\\n\")\n",
    "            \n",
    "        return (bytes_written, sp.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-opinion",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_csv(change_ext(TO_BE_PARSED, \"csv\"), ParsedFile._fields, [row._asdict() for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "loose-inside",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def is_icloud_file(filename):\n",
    "    return filename.startswith(\".\") and filename.endswith(\".icloud\")\n",
    "\n",
    "def get_name_for_icloud_file(filename):\n",
    "    return filename[1:-7]\n",
    "\n",
    "def to_lower(s):\n",
    "    return s.lower()\n",
    "\n",
    "def sort_ci(string_list):\n",
    "    return sorted(string_list, sort=to_lower)\n",
    "\n",
    "@with_real_path\n",
    "def get_files(folder):\n",
    "     return [f for f in os.listdir(folder) if isfile(join(folder, f))]\n",
    "    \n",
    "def format_long_line(long_title, maxlength=80, indent=4):\n",
    "    leader = indent * \" \"\n",
    "    long_title_length = len(long_title)\n",
    "    if long_title_length < maxlength:\n",
    "        return long_title\n",
    "    \n",
    "    long_title_words = ((w, len(w)) for w in long_title.split())\n",
    "    \n",
    "    line, lines = \"\", []\n",
    "    for word, word_length in long_title_words:\n",
    "        if len(line) + word_length > maxlength:\n",
    "            lines.append(line)\n",
    "            line = leader\n",
    "            \n",
    "        line += word + \" \"\n",
    "    \n",
    "    # append the last line after exiting the loop\n",
    "    lines.append(line)\n",
    "    return \"\\n\".join([line.rstrip() for line in lines])\n",
    "\n",
    "def print_long_lines(long_lines):\n",
    "    for line in long_lines:\n",
    "        print(format_long_line(line))\n",
    "\n",
    "files = get_files(DOWNLOADS_DIR)\n",
    "# files = [f for f in os.listdir(os.readlink(os.path.expanduser(\"~/Downloads\"))) if os.path.isfile(f)]\n",
    "icloud_files = sorted([get_name_for_icloud_file(f) for f in files if is_icloud_file(f)])\n",
    "#icloud_files = [get_name_for_icloud_file(f) for f in files if f.startswith(\".\") and f.endswith(\".icloud\")]\n",
    "local_files = sorted([f for f in files if not is_icloud_file(f)])\n",
    "\n",
    "#pprint(icloud_files)\n",
    "# pprint(local_files)\n",
    "#pprint([f for f in icloud_files if os.path.splitext(f)[1].lower() in [\".pdf\", \".mobi\", \".epub\"]])\n",
    "zlib_files = [join(DOWNLOADS_DIR, f) for f in local_files if os.path.splitext(f)[1].lower() \n",
    "                                     in [\".pdf\", \".mobi\", \".epub\"]\n",
    "                                     and re.search(r\"\\(z-lib.org\\)\", f)]\n",
    "\n",
    "zlib_files.sort(key=to_lower)\n",
    "\n",
    "delete_zlib = partial(re.sub, r\"\\s*\\(z-lib.org\\)\\s*\", \"\")\n",
    "rename_spec = [(file, delete_zlib(file)) for file in zlib_files]\n",
    "\n",
    "pprint(zlib_files, width=120)\n",
    "# print(len(zlib_files))\n",
    "\n",
    "# for rs in rename_spec:\n",
    "#     os.rename(*rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "technical-desert",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HDMI_MODE_FIELDS = \"hdmi_mode resolution frequency screen_aspect notes\".split()\n",
    "\n",
    "HDMI_mode = namedtuple(\"HDMI_mode\", HDMI_MODE_FIELDS)\n",
    "\n",
    "hdmi_modes_html_text = read_text_file(\"~/temp/hdmi_modes.html\")\n",
    "soup = read_html_text(hdmi_modes_html_text)\n",
    "rows = soup.body.table.find_all(\"tr\")\n",
    "hdmi_modes_rows = [HDMI_mode(*[td.string for td in row.find_all(\"td\")])\n",
    "                                         for row in rows[1:]]\n",
    "\n",
    "write_csv(\"~/temp/hdmi_modes.csv\", HDMI_MODE_FIELDS, [row._asdict() for row in hdmi_modes_rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "external-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPTER_NUMBER_RE = re.compile(r\"\\((\\d+)\\)\")\n",
    "LAST_NAME_RE = re.compile(r\"^\\.\\s+(\\w+)\\s*$\")\n",
    "OUTSTANDING_HEADING = \"== outstanding\"\n",
    "\n",
    "def get_chapter_number(line):\n",
    "    match = CHAPTER_NUMBER_RE.search(line)\n",
    "    if match:\n",
    "        return int(match[1])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_last_name(full_name):\n",
    "    return LAST_NAME_RE.search(full_name)[0]\n",
    "    \n",
    "def get_chapter_author_titles(chapter_numbers):\n",
    "    with Connection(TOC_FILE) as cn:\n",
    "        for chapter in chapter_numbers:\n",
    "            cur = cn.execute(GET_CHAPTER_TITLES_SQL, (chapter,))\n",
    "            yield cur.fetchone()\n",
    "\n",
    "\n",
    "GROUPINGS_FILE = \"~/Repos/music-and-letters/groupings.adoc\"\n",
    "TOC_FILE = expanduser(\"~/temp/strauss_toc.db\")\n",
    "\n",
    "GET_CHAPTER_TITLES_SQL = \"SELECT author, chapter, title\" \\\n",
    "                         \"FROM v_chapters \" \\\n",
    "                         \"WHERE chapter = ?;\"\n",
    "\n",
    "ChapterAuthorTitle = namedtuple(\"ChapterAuthorTitle\", \"chapter author title\")\n",
    "\n",
    "def ChapterAuthorTitle__repr__(self):\n",
    "    return f\"{get_last_name(self.author)} _({self.title})_ ({self.chapter})\"\n",
    "\n",
    "ChapterAuthorTitle.__repr__ = ChapterAuthorTitle__repr__\n",
    "\n",
    "lines = {line.strip() : line_num for line_num, line \n",
    "                          in enumerate(read_all_lines(GROUPINGS_FILE), start=1)\n",
    "                          if len(line.strip()) and get_chapter_number(line)\n",
    "                          or line.startswith(\"== outstanding\")}\n",
    "\n",
    "# print(\"lines\")\n",
    "# pprint(lines)\n",
    "\n",
    "outstanding_line_num = lines[OUTSTANDING_HEADING]\n",
    "\n",
    "present = [key for key in lines.keys() \n",
    "            if lines[key] != OUTSTANDING_HEADING\n",
    "            and lines[key] < outstanding_line_num]\n",
    "absent = [key for key in lines.keys() \n",
    "           if lines[key] != OUTSTANDING_HEADING\n",
    "           and lines[key] > outstanding_line_num]\n",
    "\n",
    "# pprint(present)\n",
    "pyperclip.copy(\"\\n\".join(absent))\n",
    "\n",
    "# chapters = set(sorted([get_chapter_number(line) for line in lines]))\n",
    "# print(chapters)\n",
    "# missing = [c for c in range(1, 37) if not c in chapters]\n",
    "# print(missing)\n",
    "\n",
    "# results = list(get_chapter_author_titles(missing))\n",
    "# pprint(results)\n",
    "\n",
    "# chapter_author_titles = [ChapterAuthorTitle(*c) for  in results]\n",
    "\n",
    "# bytes_written, output = list_to_string(chapter_author_titles)\n",
    "# print(f\"{bytes_written} bytes written\")\n",
    "# print(output)\n",
    "# pyperclip.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general-purpose",
   "language": "python",
   "name": "general-purpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
